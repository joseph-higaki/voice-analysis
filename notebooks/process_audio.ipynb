{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Audio Processor\n",
    "Convert audio file into metrics\n",
    "\n",
    "- [Pitch](#pitch)\n",
    "- [Intensity](#intensity)\n",
    "- [Speech Tempo](#speech-tempo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import parselmouth\n",
    "import numpy as np\n",
    "import uuid\n",
    "import pandas as pd\n",
    "import os\n",
    "import shutil\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.patches as mpatches\n",
    "import librosa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select audio file to analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_filename = \"/workspaces/voice-analysis/data/01_raw/joseph_elrion.wav\"\n",
    "audio_filename_language = \"es\"\n",
    "\n",
    "#audio_filename = \"/workspaces/voice-analysis/data/01_raw/high.wav\"\n",
    "#audio_filename_language = \"en\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some Useful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_analysis_id(audio_filename: str) -> str:\n",
    "    # Create new recording_id\n",
    "    return str(uuid.uuid4().hex)\n",
    "\n",
    "def get_destination_folder(analysis_id: str, audio_filename: str) -> str:\n",
    "    # Destination Paths folder, processed wav and csv\n",
    "    base_name, extension = os.path.splitext(os.path.basename(audio_filename))\n",
    "    return f\"/workspaces/voice-analysis/data/02_processed/{analysis_id}__{base_name}{extension}/\"\n",
    "\n",
    "def get_destination_audio_filename(analysis_id: str, audio_filename: str) -> str:\n",
    "    base_name, extension = os.path.splitext(os.path.basename(audio_filename))\n",
    "    destination_folder = get_destination_folder(analysis_id, audio_filename)\n",
    "    return os.path.join(destination_folder, f\"{analysis_id}__{base_name}{extension}\")\n",
    "\n",
    "def get_destination_analysis_filename(analysis_id: str, audio_filename: str, analysis_type: str, analysis_filename_extension: str = \"csv\") -> str:\n",
    "    base_name, extension = os.path.splitext(os.path.basename(audio_filename))\n",
    "    destination_folder = get_destination_folder(analysis_id, audio_filename)\n",
    "    return os.path.join(destination_folder, f\"{analysis_id}__{base_name}{extension}_{analysis_type}.{analysis_filename_extension}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vocal Categories ranges \n",
    "categories = {\n",
    "    'Soprano': {'range': [261.63, 1046.50], 'color': 'grey'},\n",
    "    'Mezzo-Soprano': {'range': [220.00, 880.00], 'color': 'yellow'},\n",
    "    'Alto': {'range': [174.61, 698.46], 'color': 'cyan'},\n",
    "    'Tenor': {'range': [130.81, 523.25], 'color': 'green'},\n",
    "    'Baritone': {'range': [98.00, 392.00], 'color': 'blue'},\n",
    "    'Bass': {'range': [82.41, 329.63], 'color': 'red'}\n",
    "}\n",
    "\n",
    "def draw_horizontal_shadows(plt, transparency):    \n",
    "    for  category_name, v in categories.items():\n",
    "        plt.axhspan(v[\"range\"][0], v[\"range\"][1], facecolor = v[\"color\"], alpha = transparency)            \n",
    "\n",
    "def draw_legend(plt, transparency):    \n",
    "    handle_values = []\n",
    "    for  category_name, v in categories.items():        \n",
    "        handle_values.append(mpatches.Patch(color=v[\"color\"], alpha=transparency, label= f'{category_name}-{v[\"range\"]}' ))\n",
    "    plt.legend(handles= handle_values, loc='upper left', bbox_to_anchor=(1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pitch\n",
    "Extracts frequency (Hz) of sound over a time series (seconds) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Persist Pitch Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process audio \n",
    "snd = parselmouth.Sound(audio_filename)\n",
    "# Extract Pitch timeseries\n",
    "pitch = snd.to_pitch()\n",
    "# Extract time & frequency to persist\n",
    "dfPitch = pd.DataFrame(data=zip(pitch.xs(), pitch.selected_array['frequency']), columns=[\"time\", \"frequency\"])\n",
    "\n",
    "# Create new analysis_id\n",
    "analysis_id = generate_analysis_id(audio_filename)\n",
    "destination_folder = get_destination_folder(analysis_id, audio_filename)\n",
    "destination_audio_filename = get_destination_audio_filename(analysis_id, audio_filename)\n",
    "destination_pitch_csv =  get_destination_analysis_filename(analysis_id, audio_filename, \"pitch\")\n",
    "\n",
    "# Create/ensure the folder\n",
    "os.makedirs(destination_folder, exist_ok=True)\n",
    "\n",
    "# Move the wav file to the new folder and rename it\n",
    "shutil.copy(audio_filename, destination_audio_filename)\n",
    "\n",
    "# Save data\n",
    "dfPitch.to_csv(destination_pitch_csv, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Pitch Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.dpi'] = 300\n",
    "sns.set_theme()\n",
    "\n",
    "pitch_values = pitch.selected_array['frequency']\n",
    "# NOt plotting zero values\n",
    "pitch_values[pitch_values==0] = np.nan    \n",
    "plt.plot(pitch.xs(), pitch_values, '.', markersize=4, color=\"black\")            \n",
    "plt.ylim(0, np.nanmax(pitch_values))  \n",
    "\n",
    "plt.ylabel(\"fundamental frequency [Hz]\")\n",
    "plt.xlabel(\"time [secs]\")\n",
    "\n",
    "draw_horizontal_shadows(plt, 0.2)\n",
    "draw_legend(plt, 0.4)\n",
    "\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Vocal Categories for Reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "draw_horizontal_shadows(plt, 0.2)\n",
    "#draw_legend(plt, 0.4)\n",
    "box = plt.boxplot([v[\"range\"] for v in categories.values()], patch_artist=True, tick_labels=categories.keys())\n",
    "# Set the colors for each box\n",
    "for patch, color in zip(box['boxes'], [v[\"color\"] for v in categories.values()]):\n",
    "    patch.set_facecolor(color)\n",
    "    patch.set_alpha(1)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intensity\n",
    "Extracts intensity or amplitude (dB) of sound over a time series (seconds) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Persist Intensity Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# snd SOund object already had calculated the amplitude timeseries\n",
    "dfAmplitude = pd.DataFrame(data=zip(snd.xs(), snd.values[0], snd.values[1]), columns=[\"time\", \"amplitude_left_channel\", \"amplitude_right_channel\"])\n",
    "destination_amplitude_csv =  get_destination_analysis_filename(analysis_id, audio_filename, \"amplitude\")\n",
    "# Save csvs\n",
    "#dfAmplitude.to_csv(destination_amplitude_csv, index=False)\n",
    "destination_amplitude_parquet =  get_destination_analysis_filename(analysis_id, audio_filename, \"amplitude\", \"parquet\")\n",
    "dfAmplitude.to_parquet(destination_amplitude_parquet, index=False)\n",
    "\n",
    "\n",
    "# Extract intensity timeseries\n",
    "intensity = snd.to_intensity()\n",
    "dfIntensity = pd.DataFrame(data=zip(intensity.xs(), intensity.values.T), columns=[\"time\", \"intensity\"])\n",
    "destination_intensity_csv =  get_destination_analysis_filename(analysis_id, audio_filename, \"intensity\")\n",
    "# Save csvs\n",
    "dfIntensity.to_csv(destination_intensity_csv, index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "fig, ax1 = plt.subplots(figsize=(12, 6)) \n",
    "# Plot the left channel\n",
    "ax1.plot(snd.xs(), snd.values[0], color='blue', label='Left Channel')\n",
    "\n",
    "# Plot the right channel\n",
    "ax1.plot(snd.xs(), snd.values[1], color='green', label='Right Channel')\n",
    "\n",
    "ax1.set_xlabel(\"time [s]\")\n",
    "ax1.set_ylabel(\"amplitude [Pa]\")\n",
    "ax1.legend()\n",
    "fig.tight_layout()  # Adjust layout to prevent overlap\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(intensity.xs(), intensity.values.T)\n",
    "plt.xlabel(\"time [s]\")\n",
    "plt.ylabel(\"intensity [dB]\")\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming snd and intensity are already defined\n",
    "fig, ax1 = plt.subplots(figsize=(20, 4))\n",
    "\n",
    "# Plot the amplitude on the first y-axis\n",
    "ax1.plot(snd.xs(), snd.values.T, color='blue')\n",
    "ax1.set_xlabel(\"time [s]\")\n",
    "ax1.set_ylabel(\"relative amplitude\", color='blue')\n",
    "ax1.tick_params(axis='y', labelcolor='blue')\n",
    "\n",
    "# Create a second y-axis for the intensity\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(intensity.xs(), intensity.values.T, color='red')\n",
    "ax2.set_ylabel(\"intensity [dB]\", color='red')\n",
    "ax2.tick_params(axis='y', labelcolor='red')\n",
    "\n",
    "# Show the plot\n",
    "fig.tight_layout()  # Adjust layout to prevent overlap\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speech Tempo\n",
    "The best measure I could find is Words per minute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try simple speech recognition for word count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Free Google Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import speech_recognition as sr\n",
    "# Initialize recognizer\n",
    "recognizer = sr.Recognizer()\n",
    "# Load the audio file\n",
    "with sr.AudioFile(audio_filename) as source:\n",
    "    audio_data = recognizer.record(source)\n",
    "    # Recognize speech using Google Web Speech API\n",
    "    text_by_google = recognizer.recognize_google(audio_data, language=audio_filename_language)\n",
    "    print(\"Transcription by Google:\", text_by_google)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pocket Shpinx Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sphinx_language_parameter = {\\\n",
    "    \"es\": (\\\n",
    "    \"/workspaces/voice-analysis/dependency/pocketsphinx_language/cmusphinx-es-5.2/cmusphinx-es-5.2/model_parameters/voxforge_es_sphinx.cd_ptm_4000\",\\\n",
    "    \"/workspaces/voice-analysis/dependency/pocketsphinx_language/es-20k.lm.gz\",\\\n",
    "    \"/workspaces/voice-analysis/dependency/pocketsphinx_language/es.dict\"\n",
    "    ),\n",
    "    \"en\": \"en-US\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with sr.AudioFile(audio_filename) as source:\n",
    "    audio_data = recognizer.record(source)\n",
    "    # Recognize speech using Google Web Speech API\n",
    "    text_by_sphinx = recognizer.recognize_sphinx(audio_data, sphinx_language_parameter[audio_filename_language])\n",
    "    print(\"Transcription by sphinx:\", text_by_sphinx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wave\n",
    "\n",
    "duration_seconds = 0\n",
    "with wave.open(audio_filename, \"rb\") as wav_file:\n",
    "    # Get the number of frames in the file\n",
    "    frames = wav_file.getnframes()\n",
    "    # Get the frame rate (number of frames per second)\n",
    "    frame_rate = wav_file.getframerate()\n",
    "    # Calculate the duration in seconds\n",
    "    duration_seconds = frames / float(frame_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wpm(text: str, duration_seconds: float) -> float:\n",
    "    words = text.split()\n",
    "    word_count = len(words)\n",
    "    #print(words)\n",
    "    return (word_count / duration_seconds) * 60\n",
    "wpm_by_google = get_wpm(text_by_google, duration_seconds)\n",
    "wpm_by_sphinx = get_wpm(text_by_sphinx, duration_seconds)\n",
    "print(f\"WPM by Google {wpm_by_google}\")\n",
    "print(f\"WPM by Sphinx {wpm_by_sphinx}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_speech_tempo = pd.DataFrame(\\\n",
    "    data = zip(\\\n",
    "        [\"google_speech_api\", \"pocketsphinx\"],\\\n",
    "        [\"recognizer.recognize_google\", \"recognizer.recognize_sphinx\"],\\\n",
    "        [audio_filename_language, audio_filename_language], \\\n",
    "        [audio_filename_language, sphinx_language_parameter[audio_filename_language]],\\\n",
    "        [text_by_google, text_by_sphinx], \\\n",
    "        [wpm_by_google, wpm_by_sphinx]\n",
    "        ),\\\n",
    "    columns=\\\n",
    "        [\"transcript_provider\", \"transcript_function\", \"user_input_language\", \"provider_language_parameter\", \"provider_transcript\", \"provider_wpm\" ]\n",
    "        )\n",
    "destination_speech_tempo_csv =  get_destination_analysis_filename(analysis_id, audio_filename, \"speech_tempo\")\n",
    "# Save csvs\n",
    "df_speech_tempo.to_csv(destination_speech_tempo_csv, index=False)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabulate import tabulate\n",
    "\n",
    "print(tabulate(df_speech_tempo, headers='keys', showindex=False, tablefmt=\"github\" ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_formats = [\"plain\",\n",
    "\"simple\",\n",
    "\"github\",\n",
    "\"grid\",\n",
    "\"simple_grid\",\n",
    "\"rounded_grid\",\n",
    "\"heavy_grid\",\n",
    "\"mixed_grid\",\n",
    "\"double_grid\",\n",
    "\"fancy_grid\",\n",
    "\"outline\",\n",
    "\"simple_outline\",\n",
    "\"rounded_outline\",\n",
    "\"heavy_outline\",\n",
    "\"mixed_outline\",\n",
    "\"double_outline\",\n",
    "\"fancy_outline\",\n",
    "\"pipe\",\n",
    "\"orgtbl\",\n",
    "\"asciidoc\",\n",
    "\"jira\",\n",
    "\"presto\",\n",
    "\"pretty\",\n",
    "\"psql\",\n",
    "\"rst\",\n",
    "\"mediawiki\",\n",
    "\"moinmoin\",\n",
    "\"youtrack\",\n",
    "\"html\",\n",
    "\"unsafehtml\",\n",
    "\"latex\",\n",
    "\"latex_raw\",\n",
    "\"latex_booktabs\",\n",
    "\"latex_longtable\",\n",
    "\"textile\",\n",
    "\"tsv\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_tabulate_table(t:str):\n",
    "    print(f\"************************\")\n",
    "    print(f\"************************\")\n",
    "    print(f\"*** {t} ****\")\n",
    "    print(tabulate(df_speech_tempo, headers='keys', showindex=False, tablefmt=t )) \n",
    "\n",
    "\n",
    "[ print_tabulate_table(t) for t in table_formats]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
